{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jVHvt1sRoLf"
      },
      "source": [
        "This notebook explains the bais in the data for RACE with respoect to Frisk. Below are the steps to check the bais in the data or not:\n",
        "1. Group races into privileged & unprivileged categorie\n",
        "2. Compute fairness metrics for each racial group\n",
        "    * Chi Square test\n",
        "    * Disparate impact\n",
        "    * Statistical parity\n",
        "    * Equal opportunity difference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NtROrQOhRoLi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6awZurq4RoLk",
        "outputId": "ebdb114f-bfea-4c9c-9309-d3e9c3fe83b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2017 : (11629, 84)\n",
            "2018 : (11008, 84)\n",
            "2019 : (13459, 84)\n",
            "2020 : (9544, 84)\n",
            "2021 : (8947, 84)\n",
            "2022 : (15102, 83)\n",
            "2023 : (16971, 83)\n"
          ]
        }
      ],
      "source": [
        "years = [2017,2018,2019,2020,2021,2022,2023]\n",
        "\n",
        "files=['sqf-2017.xlsx',\n",
        " 'sqf-2018.xlsx',\n",
        " 'sqf-2019.xlsx',\n",
        " 'sqf-2020.xlsx',\n",
        " 'sqf-2021.xlsx',\n",
        " 'sqf-2022.xlsx',\n",
        " 'sqf-2023.xlsx',\n",
        " ]\n",
        "\n",
        "df = pd.read_excel('./sqf-2024.xlsx')\n",
        "for file,year in zip(files,years):\n",
        "    df_year = pd.read_excel(file)\n",
        "    df_year['year'] = year\n",
        "    cols = [col for col in df.columns if col in df_year.columns]\n",
        "    print(f\"{year} : {df_year.shape}\")\n",
        "    df = pd.concat([df,df_year[cols]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AFePhN6YRoLm"
      },
      "outputs": [],
      "source": [
        "RACE = 'SUSPECT_RACE_DESCRIPTION'\n",
        "target = 'FRISKED_FLAG'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "AgMIbuNWRoLn",
        "outputId": "0de0ba78-c69f-4437-b30f-a6a76e66f768"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FRISKED_FLAG\n",
              "Y    67213\n",
              "N    44832\n",
              "V        1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FRISKED_FLAG</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Y</th>\n",
              "      <td>67213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>N</th>\n",
              "      <td>44832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df[target].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXtaYaZRRoLn",
        "outputId": "d2bd53ae-0777-4be4-d6b8-7bf4519f09d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((109807, 81), (112046, 81))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "df_filter = df[~df.SUSPECT_RACE_DESCRIPTION.isin(['(null)','MALE'])]\n",
        "df_filter.shape,df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "6tbw2ABxRoLo"
      },
      "outputs": [],
      "source": [
        "df_filter['SUSPECT_RACE_DESCRIPTION'] = np.where(df_filter['SUSPECT_RACE_DESCRIPTION']=='ASIAN/PAC.ISL','ASIAN / PACIFIC ISLANDER',df_filter['SUSPECT_RACE_DESCRIPTION'])\n",
        "df_filter['SUSPECT_RACE_DESCRIPTION'] = np.where(df_filter['SUSPECT_RACE_DESCRIPTION']=='MIDDLE EASTERN/SOUTHWEST','MIDDLE EASTERN/SOUTHWEST ASIAN',df_filter['SUSPECT_RACE_DESCRIPTION'])\n",
        "df_filter['SUSPECT_RACE_DESCRIPTION'] = np.where(df_filter['SUSPECT_RACE_DESCRIPTION']=='AMERICAN INDIAN/ALASKAN N','AMERICAN INDIAN/ALASKAN NATIVE',df_filter['SUSPECT_RACE_DESCRIPTION'])\n",
        "df_filter['SUSPECT_RACE_DESCRIPTION'] = np.where(df_filter['SUSPECT_RACE_DESCRIPTION']=='AMER IND','AMERICAN INDIAN/ALASKAN NATIVE',df_filter['SUSPECT_RACE_DESCRIPTION'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "WKhzNXt_RoLp",
        "outputId": "9eb2426b-0c03-48d5-d9e2-0db5d1485889"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SUSPECT_RACE_DESCRIPTION\n",
              "BLACK                             0.592421\n",
              "WHITE HISPANIC                    0.210788\n",
              "BLACK HISPANIC                    0.093983\n",
              "WHITE                             0.075041\n",
              "ASIAN / PACIFIC ISLANDER          0.019871\n",
              "MIDDLE EASTERN/SOUTHWEST ASIAN    0.006566\n",
              "AMERICAN INDIAN/ALASKAN NATIVE    0.001330\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SUSPECT_RACE_DESCRIPTION</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BLACK</th>\n",
              "      <td>0.592421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WHITE HISPANIC</th>\n",
              "      <td>0.210788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BLACK HISPANIC</th>\n",
              "      <td>0.093983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WHITE</th>\n",
              "      <td>0.075041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ASIAN / PACIFIC ISLANDER</th>\n",
              "      <td>0.019871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIDDLE EASTERN/SOUTHWEST ASIAN</th>\n",
              "      <td>0.006566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMERICAN INDIAN/ALASKAN NATIVE</th>\n",
              "      <td>0.001330</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "df_filter['SUSPECT_RACE_DESCRIPTION'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "kku-EthsRoLp"
      },
      "outputs": [],
      "source": [
        "feats=['BACKROUND_CIRCUMSTANCES_VIOLENT_CRIME_FLAG',\n",
        "       'SUSPECTED_CRIME_DESCRIPTION',\n",
        "       'SUSPECTS_ACTIONS_CONCEALED_POSSESSION_WEAPON_FLAG','STOP_LOCATION_X','STOP_LOCATION_Y',\n",
        "       'STOP_WAS_INITIATED','STOP_DURATION_MINUTES','STOP_FRISK_TIME','SUSPECT_REPORTED_AGE',\n",
        "       'SUSPECT_HEIGHT','SUSPECT_WEIGHT','SUSPECT_SEX',\n",
        "       'SUSPECT_RACE_DESCRIPTION','SEARCHED_FLAG','SEARCH_BASIS_HARD_OBJECT_FLAG',\n",
        "       'CONSENT_GIVEN_FLG','FRISKED_FLAG']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter = df_filter[df_filter.STOP_WAS_INITIATED!='(null)']\n",
        "df_filter['BACKROUND_CIRCUMSTANCES_VIOLENT_CRIME_FLAG'] = np.where(df_filter.BACKROUND_CIRCUMSTANCES_VIOLENT_CRIME_FLAG=='(null)',0,1)\n",
        "df_filter['SUSPECTS_ACTIONS_CONCEALED_POSSESSION_WEAPON_FLAG'] = np.where(df_filter.SUSPECTS_ACTIONS_CONCEALED_POSSESSION_WEAPON_FLAG=='(null)',0,1)\n",
        "df_filter['SUSPECT_SEX'] = np.where(df_filter.SUSPECT_SEX=='(null)','UNKNOWN',df_filter.SUSPECT_SEX)\n",
        "df_filter['SEARCHED_FLAG'] = np.where(df_filter.SEARCHED_FLAG=='Y',1,0)\n",
        "df_filter['SEARCH_BASIS_HARD_OBJECT_FLAG'] = np.where(df_filter.SEARCH_BASIS_HARD_OBJECT_FLAG=='(null)',0,1)\n",
        "\n",
        "df_filter['CONSENT_GIVEN_FLG'] = np.where(df_filter.CONSENT_GIVEN_FLG.isin(['(null)','(']),'U',df_filter.CONSENT_GIVEN_FLG)\n",
        "df_filter['FRISKED_FLAG'] = np.where(df_filter.FRISKED_FLAG=='Y',1,0)\n",
        "\n",
        "df_filter['SUSPECT_HEIGHT'] = np.where(df_filter.SUSPECT_HEIGHT.isin(['(null)',' ']),None,df_filter.SUSPECT_HEIGHT)\n",
        "df_filter['SUSPECT_HEIGHT'] = df_filter.SUSPECT_HEIGHT.astype(float)\n",
        "df_filter['SUSPECT_HEIGHT'] = df_filter.SUSPECT_HEIGHT.fillna(df_filter.SUSPECT_HEIGHT.mean())\n",
        "\n",
        "df_filter['SUSPECT_WEIGHT'] = np.where(df_filter.SUSPECT_WEIGHT.isin(['(null)',' ']),None,df_filter.SUSPECT_WEIGHT)\n",
        "df_filter['SUSPECT_WEIGHT'] = df_filter.SUSPECT_WEIGHT.astype(float)\n",
        "df_filter['SUSPECT_WEIGHT'] = df_filter.SUSPECT_WEIGHT.fillna(df_filter.SUSPECT_WEIGHT.mean())\n",
        "\n",
        "df_filter['SUSPECT_REPORTED_AGE'] = np.where(df_filter.SUSPECT_REPORTED_AGE.isin(['(null)',' ']),None,df_filter.SUSPECT_REPORTED_AGE)\n",
        "df_filter['SUSPECT_REPORTED_AGE'] = df_filter.SUSPECT_REPORTED_AGE.astype(float)\n",
        "df_filter['SUSPECT_REPORTED_AGE'] = df_filter.SUSPECT_REPORTED_AGE.fillna(df_filter.SUSPECT_REPORTED_AGE.mean())\n",
        "\n"
      ],
      "metadata": {
        "id": "K2bd5f6_SkA7"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check Bias across multiple races"
      ],
      "metadata": {
        "id": "F8chlLioS0Lw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Chi-Square Test of Independence** is used to determine whether there is a statistically significant relationship between two categorical variables—in this case, race and frisking outcomes. It helps identify potential bias in stop-and-frisk practices.\n",
        "\n",
        "##### Methodology:\n",
        "1. Construct a contingency table that records the number of frisked and non-frisked individuals across different racial groups.\n",
        "2. Compute the Chi-Square statistic using the formula:<br>\n",
        "$$χ^{2} = \\sum \\frac{(O - E)^{2}}{E} $$\n",
        "\n",
        " where:\n",
        "\n",
        "  * O = observed frequency in each category\n",
        "\n",
        "  * E = expected frequency if there were no racial bias\n",
        "\n",
        "3. Obtain the **p-value** to test the null hypothesis (H₀: Frisking is independent of race).\n",
        "4. Compare the p-value with a significance level (𝛼=0.05):\n",
        "  * p < 0.05 → Reject H₀ → Indicates a significant racial disparity (potential bias).\n",
        "  * p ≥ 0.05 → Fail to reject H₀ → No strong evidence of bias.\n",
        "\n",
        "##### Results Interpretation:\n",
        "* A **significant Chi-Square** result suggests racial bias in frisking, indicating that race influences frisking outcomes.\n",
        "* If the test does not find a significant difference, it means frisking is distributed proportionally across racial groups.\n",
        "\n",
        "This test provides an initial statistical check for bias, which is further validated using fairness metrics like Equal Opportunity Difference, Disparate Impact, and Statistical Parity Difference. If bias is detected, bias mitigation techniques (such as reweighing or adversarial debiasing) are applied to ensure fairness in predictive models.\n",
        "\n"
      ],
      "metadata": {
        "id": "stR3sS0WIdYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "# Creating a contingency table\n",
        "contingency_table = pd.crosstab(df_filter['SUSPECT_RACE_DESCRIPTION'], df_filter['FRISKED_FLAG'])\n",
        "\n",
        "# Perform the chi-square test\n",
        "chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "# Display results\n",
        "print(\"Chi-square Statistic:\", chi2)\n",
        "print(\"P-value:\", p)\n",
        "print(\"Degrees of Freedom:\", dof)\n",
        "print(\"Expected Frequencies:\\n\", expected)\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05  # Significance level\n",
        "if p < alpha:\n",
        "    print(\"There is a statistically significant relationship between RACE and FRISKED. Potential bias detected.\")\n",
        "else:\n",
        "    print(\"No statistically significant relationship found. No strong evidence of bias in frisking.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5mcVQKqDFRE",
        "outputId": "41554264-096e-4525-b7fe-acc4402987fc"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-square Statistic: 2115.8903256843155\n",
            "P-value: 0.0\n",
            "Degrees of Freedom: 6\n",
            "Expected Frequencies:\n",
            " [[   58.94174545    87.05825455]\n",
            " [  880.89649708  1301.10350292]\n",
            " [26260.56615116 38787.43384884]\n",
            " [ 4164.67839773  6151.32160227]\n",
            " [  291.07533199   429.92466801]\n",
            " [ 3326.1715121   4912.8284879 ]\n",
            " [ 9342.6703645  13799.3296355 ]]\n",
            "There is a statistically significant relationship between RACE and FRISKED. Potential bias detected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate potential racial bias in frisking outcomes, we use three key fairness metrics: Equal Opportunity Difference (EOD), Disparate Impact (DI), and Statistical Parity Difference (SPD). These metrics help quantify disparities between privileged and unprivileged racial groups.\n",
        "\n",
        "##### 1. Equal Opportunity Difference (EOD)\n",
        "**Definition:** Measures the difference in frisking rates between unprivileged and privileged groups, conditioned on positive outcomes (i.e., individuals who should have been frisked).\n",
        "\n",
        "$EOD=P(Frisked∣Unprivileged Group, Should Be Frisked)−P(Frisked∣Privileged Group, Should Be Frisked)$\n",
        "\n",
        "**Interpretation:**\n",
        "* EOD = 0 → No disparity; both groups have equal frisking rates for relevant cases.\n",
        "* EOD > 0 → Unprivileged group is frisked more than the privileged group.\n",
        "* EOD < 0 → Unprivileged group is frisked less than the privileged group (potential under-policing).\n",
        "* A large deviation from zero indicates possible discrimination.\n",
        "\n",
        "##### 2. Disparate Impact (DI)\n",
        "**Definition:** Measures the ratio of frisking rates between the unprivileged and privileged groups.\n",
        "\n",
        "$$DI= \\frac{P(Frisked∣Unprivileged Group)}{P(Frisked∣Privileged Group)}$$\n",
        "\n",
        "**Interpretation:**\n",
        "* DI = 1 → No bias; both groups have equal frisking rates.\n",
        "* DI < 0.8 → Strong evidence of bias against the unprivileged group (per U.S. Equal Employment Opportunity Commission guidelines).\n",
        "* DI > 1.25 → Potential bias in favor of the unprivileged group.\n",
        "\n",
        "##### 3. Statistical Parity Difference (SPD)\n",
        "**Definition:** Measures the difference in overall frisking rates between unprivileged and privileged groups.\n",
        "\n",
        "$$SPD=P(Frisked∣Unprivileged Group)−P(Frisked∣Privileged Group)$$\n",
        "\n",
        "**Interpretation:**\n",
        "* SPD = 0 → No disparity.\n",
        "* SPD > 0 → Unprivileged group is frisked more than the privileged group.\n",
        "* SPD < 0 → Unprivileged group is frisked less than the privileged group.\n",
        "* A larger absolute value suggests potential bias.\n",
        "\n",
        "These metrics provide a deeper understanding of how frisking outcomes differ across racial groups. If significant bias is detected, mitigation strategies such as Reweighing (Pre-processing) and Adversarial Debiasing (In-processing) are applied to improve fairness while maintaining model performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZhVLk_4HSMol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bias Metrics Calculation\n",
        "def calculate_bias_metrics(df, privileged_race):\n",
        "    race_groups = df['SUSPECT_RACE_DESCRIPTION'].unique()\n",
        "\n",
        "    rates = {}\n",
        "    for race in race_groups:\n",
        "        frisked_rate = df[df['SUSPECT_RACE_DESCRIPTION'] == race]['FRISKED_FLAG'].mean()\n",
        "        rates[race] = frisked_rate\n",
        "\n",
        "    privileged_rate = rates[privileged_race]\n",
        "    print(f\"privileged_rate : {privileged_rate}\")\n",
        "    print(f\"rates : {rates}\")\n",
        "\n",
        "    # Equal Opportunity Difference (EOD)\n",
        "    eod = {race: rates[race] - privileged_rate for race in rates}\n",
        "\n",
        "    # Disparate Impact (DI)\n",
        "    di = {race: rates[race] / privileged_rate if privileged_rate > 0 else None for race in rates}\n",
        "\n",
        "    # Statistical Parity Difference (SPD)\n",
        "    spd = eod.copy()\n",
        "\n",
        "    return eod, di, spd\n",
        "\n",
        "# Choose a privileged race (modify as needed)\n",
        "privileged_race = 'WHITE HISPANIC'\n",
        "\n",
        "eod, di, spd = calculate_bias_metrics(df_filter, privileged_race)\n",
        "\n",
        "print(\"\\nEqual Opportunity Difference:\", eod)\n",
        "print(\"Disparate Impact:\", di)\n",
        "print(\"Statistical Parity Difference:\", spd)\n",
        "\n",
        "# Bias Interpretation\n",
        "bias_threshold = 0.8  # Disparate impact threshold\n",
        "for race in di:\n",
        "    if di[race] is not None and di[race] < bias_threshold:\n",
        "        print(f\"Potential bias detected against {race} with Disparate Impact below threshold.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEsXZcro7Em3",
        "outputId": "6f1e0744-cf60-4169-e0bf-f1b149dea9b0"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "privileged_rate : 0.5790337913749892\n",
            "rates : {'WHITE HISPANIC': np.float64(0.5790337913749892), 'BLACK': np.float64(0.6296427253720329), 'BLACK HISPANIC': np.float64(0.6308646762310973), 'WHITE': np.float64(0.3846340575312538), 'MIDDLE EASTERN/SOUTHWEST ASIAN': np.float64(0.47295423023578365), 'ASIAN / PACIFIC ISLANDER': np.float64(0.4738771769019248), 'AMERICAN INDIAN/ALASKAN NATIVE': np.float64(0.410958904109589)}\n",
            "\n",
            "Equal Opportunity Difference: {'WHITE HISPANIC': np.float64(0.0), 'BLACK': np.float64(0.05060893399704369), 'BLACK HISPANIC': np.float64(0.051830884856108095), 'WHITE': np.float64(-0.19439973384373543), 'MIDDLE EASTERN/SOUTHWEST ASIAN': np.float64(-0.10607956113920558), 'ASIAN / PACIFIC ISLANDER': np.float64(-0.1051566144730644), 'AMERICAN INDIAN/ALASKAN NATIVE': np.float64(-0.1680748872654002)}\n",
            "Disparate Impact: {'WHITE HISPANIC': np.float64(1.0), 'BLACK': np.float64(1.0874023843701184), 'BLACK HISPANIC': np.float64(1.089512711741795), 'WHITE': np.float64(0.6642687581633041), 'MIDDLE EASTERN/SOUTHWEST ASIAN': np.float64(0.81679901463556), 'ASIAN / PACIFIC ISLANDER': np.float64(0.8183929573033092), 'AMERICAN INDIAN/ALASKAN NATIVE': np.float64(0.7097321611122469)}\n",
            "Statistical Parity Difference: {'WHITE HISPANIC': np.float64(0.0), 'BLACK': np.float64(0.05060893399704369), 'BLACK HISPANIC': np.float64(0.051830884856108095), 'WHITE': np.float64(-0.19439973384373543), 'MIDDLE EASTERN/SOUTHWEST ASIAN': np.float64(-0.10607956113920558), 'ASIAN / PACIFIC ISLANDER': np.float64(-0.1051566144730644), 'AMERICAN INDIAN/ALASKAN NATIVE': np.float64(-0.1680748872654002)}\n",
            "Potential bias detected against WHITE with Disparate Impact below threshold.\n",
            "Potential bias detected against AMERICAN INDIAN/ALASKAN NATIVE with Disparate Impact below threshold.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install aif360\n",
        "# !pip install aif360[Reductions]\n",
        "# !pip install aif360[AdversarialDebiasing]\n",
        "# !pip install aif360[inFairness]\n",
        "# !pip install tensorflow"
      ],
      "metadata": {
        "id": "7fyA7_pU_2Kr"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
        "from aif360.datasets import StandardDataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import tensorflow as tf\n",
        "#from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "2iojV8Q5S4yN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "req_feats=['BACKROUND_CIRCUMSTANCES_VIOLENT_CRIME_FLAG',\n",
        "       'SUSPECTED_CRIME_DESCRIPTION',\n",
        "       'SUSPECTS_ACTIONS_CONCEALED_POSSESSION_WEAPON_FLAG',\n",
        "       'STOP_WAS_INITIATED','STOP_DURATION_MINUTES','STOP_FRISK_TIME','SUSPECT_REPORTED_AGE',\n",
        "       'SUSPECT_HEIGHT','SUSPECT_WEIGHT','SUSPECT_SEX',\n",
        "       'SUSPECT_RACE_DESCRIPTION','SEARCHED_FLAG','SEARCH_BASIS_HARD_OBJECT_FLAG',\n",
        "       'CONSENT_GIVEN_FLG','FRISKED_FLAG']\n",
        "cat_feats = ['STOP_WAS_INITIATED','SUSPECT_SEX',\n",
        "             'CONSENT_GIVEN_FLG','SUSPECTED_CRIME_DESCRIPTION']\n",
        "\n",
        "df_filter = df_filter[req_feats]\n",
        "\n",
        "df_filter = pd.get_dummies(df_filter,columns=cat_feats)\n",
        "df_filter.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "4WImxOrsCW8s",
        "outputId": "e27918fe-6e9a-4689-d1f3-a84b6dd97de2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   BACKROUND_CIRCUMSTANCES_VIOLENT_CRIME_FLAG  \\\n",
              "0                                           0   \n",
              "1                                           0   \n",
              "2                                           0   \n",
              "3                                           0   \n",
              "4                                           0   \n",
              "\n",
              "   SUSPECTS_ACTIONS_CONCEALED_POSSESSION_WEAPON_FLAG  STOP_DURATION_MINUTES  \\\n",
              "0                                                  1                      1   \n",
              "1                                                  1                      3   \n",
              "2                                                  0                     20   \n",
              "3                                                  0                     20   \n",
              "4                                                  0                     20   \n",
              "\n",
              "  STOP_FRISK_TIME  SUSPECT_REPORTED_AGE  SUSPECT_HEIGHT  SUSPECT_WEIGHT  \\\n",
              "0        01:58:00                  27.0            5.11           160.0   \n",
              "1        00:48:00                  22.0            6.10           200.0   \n",
              "2        01:10:00                  17.0            6.00           140.0   \n",
              "3        01:10:00                  13.0            5.00           120.0   \n",
              "4        01:10:00                  14.0            5.00           120.0   \n",
              "\n",
              "  SUSPECT_RACE_DESCRIPTION  SEARCHED_FLAG  SEARCH_BASIS_HARD_OBJECT_FLAG  ...  \\\n",
              "0           WHITE HISPANIC              1                              1  ...   \n",
              "1                    BLACK              1                              1  ...   \n",
              "2           WHITE HISPANIC              0                              0  ...   \n",
              "3           WHITE HISPANIC              0                              0  ...   \n",
              "4           WHITE HISPANIC              0                              0  ...   \n",
              "\n",
              "   SUSPECTED_CRIME_DESCRIPTION_MURDER  SUSPECTED_CRIME_DESCRIPTION_OTHER  \\\n",
              "0                               False                              False   \n",
              "1                               False                              False   \n",
              "2                               False                              False   \n",
              "3                               False                              False   \n",
              "4                               False                              False   \n",
              "\n",
              "   SUSPECTED_CRIME_DESCRIPTION_PETIT LARCENY  \\\n",
              "0                                      False   \n",
              "1                                      False   \n",
              "2                                      False   \n",
              "3                                      False   \n",
              "4                                      False   \n",
              "\n",
              "   SUSPECTED_CRIME_DESCRIPTION_PROSTITUTION  SUSPECTED_CRIME_DESCRIPTION_RAPE  \\\n",
              "0                                     False                             False   \n",
              "1                                     False                             False   \n",
              "2                                     False                             False   \n",
              "3                                     False                             False   \n",
              "4                                     False                             False   \n",
              "\n",
              "   SUSPECTED_CRIME_DESCRIPTION_RECKLESS ENDANGERMENT  \\\n",
              "0                                              False   \n",
              "1                                              False   \n",
              "2                                              False   \n",
              "3                                              False   \n",
              "4                                              False   \n",
              "\n",
              "   SUSPECTED_CRIME_DESCRIPTION_ROBBERY  SUSPECTED_CRIME_DESCRIPTION_TERRORISM  \\\n",
              "0                                False                                  False   \n",
              "1                                False                                  False   \n",
              "2                                False                                  False   \n",
              "3                                False                                  False   \n",
              "4                                False                                  False   \n",
              "\n",
              "   SUSPECTED_CRIME_DESCRIPTION_THEFT OF SERVICES  \\\n",
              "0                                          False   \n",
              "1                                          False   \n",
              "2                                          False   \n",
              "3                                          False   \n",
              "4                                          False   \n",
              "\n",
              "   SUSPECTED_CRIME_DESCRIPTION_UNAUTHORIZED USE OF A VEHICLE  \n",
              "0                                              False          \n",
              "1                                              False          \n",
              "2                                              False          \n",
              "3                                              False          \n",
              "4                                              False          \n",
              "\n",
              "[5 rows x 48 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64078d9e-ebfc-45f7-b903-0933359c1a05\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BACKROUND_CIRCUMSTANCES_VIOLENT_CRIME_FLAG</th>\n",
              "      <th>SUSPECTS_ACTIONS_CONCEALED_POSSESSION_WEAPON_FLAG</th>\n",
              "      <th>STOP_DURATION_MINUTES</th>\n",
              "      <th>STOP_FRISK_TIME</th>\n",
              "      <th>SUSPECT_REPORTED_AGE</th>\n",
              "      <th>SUSPECT_HEIGHT</th>\n",
              "      <th>SUSPECT_WEIGHT</th>\n",
              "      <th>SUSPECT_RACE_DESCRIPTION</th>\n",
              "      <th>SEARCHED_FLAG</th>\n",
              "      <th>SEARCH_BASIS_HARD_OBJECT_FLAG</th>\n",
              "      <th>...</th>\n",
              "      <th>SUSPECTED_CRIME_DESCRIPTION_MURDER</th>\n",
              "      <th>SUSPECTED_CRIME_DESCRIPTION_OTHER</th>\n",
              "      <th>SUSPECTED_CRIME_DESCRIPTION_PETIT LARCENY</th>\n",
              "      <th>SUSPECTED_CRIME_DESCRIPTION_PROSTITUTION</th>\n",
              "      <th>SUSPECTED_CRIME_DESCRIPTION_RAPE</th>\n",
              "      <th>SUSPECTED_CRIME_DESCRIPTION_RECKLESS ENDANGERMENT</th>\n",
              "      <th>SUSPECTED_CRIME_DESCRIPTION_ROBBERY</th>\n",
              "      <th>SUSPECTED_CRIME_DESCRIPTION_TERRORISM</th>\n",
              "      <th>SUSPECTED_CRIME_DESCRIPTION_THEFT OF SERVICES</th>\n",
              "      <th>SUSPECTED_CRIME_DESCRIPTION_UNAUTHORIZED USE OF A VEHICLE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>01:58:00</td>\n",
              "      <td>27.0</td>\n",
              "      <td>5.11</td>\n",
              "      <td>160.0</td>\n",
              "      <td>WHITE HISPANIC</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>00:48:00</td>\n",
              "      <td>22.0</td>\n",
              "      <td>6.10</td>\n",
              "      <td>200.0</td>\n",
              "      <td>BLACK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>01:10:00</td>\n",
              "      <td>17.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>140.0</td>\n",
              "      <td>WHITE HISPANIC</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>01:10:00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>120.0</td>\n",
              "      <td>WHITE HISPANIC</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>01:10:00</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>120.0</td>\n",
              "      <td>WHITE HISPANIC</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 48 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64078d9e-ebfc-45f7-b903-0933359c1a05')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-64078d9e-ebfc-45f7-b903-0933359c1a05 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-64078d9e-ebfc-45f7-b903-0933359c1a05');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-47d7ac05-72db-4696-94ae-46add893e126\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47d7ac05-72db-4696-94ae-46add893e126')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-47d7ac05-72db-4696-94ae-46add893e126 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_filter"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_filter.STOP_FRISK_TIME.value_counts()\n",
        "\n",
        "time_cat = pd.to_datetime(df_filter['STOP_FRISK_TIME'], errors='coerce').dt.time\n",
        "# Function to categorize time\n",
        "def categorize_time(t):\n",
        "    if pd.isna(t):\n",
        "        return 'Unknown'  # Or use 'NaN' / 'Missing'\n",
        "    elif t >= pd.to_datetime('05:00', format='%H:%M').time() and t < pd.to_datetime('12:00', format='%H:%M').time():\n",
        "        return 'Morning'\n",
        "    elif t >= pd.to_datetime('12:00', format='%H:%M').time() and t < pd.to_datetime('17:00', format='%H:%M').time():\n",
        "        return 'Afternoon'\n",
        "    elif t >= pd.to_datetime('17:00', format='%H:%M').time() and t < pd.to_datetime('21:00', format='%H:%M').time():\n",
        "        return 'Evening'\n",
        "    else:\n",
        "        return 'Night'\n",
        "\n",
        "#df['time_of_day'] =\n",
        "df_filter['time_of_day'] = time_cat.apply(categorize_time)\n",
        "df_filter = pd.get_dummies(df_filter,columns=['time_of_day'])\n",
        "df_filter = df_filter.drop(columns=['STOP_FRISK_TIME'])"
      ],
      "metadata": {
        "id": "XjDbBuwCDBlK"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bias Mitigation using Reweighing from AIF360\n",
        "sensitive_attribute = 'SUSPECT_RACE_DESCRIPTION'\n",
        "target_attribute = 'FRISKED_FLAG'\n",
        "\n",
        "dataset = StandardDataset(df_filter,\n",
        "                          label_name=target_attribute,\n",
        "                          favorable_classes=[1],\n",
        "                          protected_attribute_names=[sensitive_attribute],\n",
        "                          privileged_classes=[['WHITE']])"
      ],
      "metadata": {
        "id": "zakxDb6-Bq2B"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Reweighing\n",
        "reweighing = Reweighing(unprivileged_groups=[{sensitive_attribute: race} for race in df['SUSPECT_RACE_DESCRIPTION'].unique() if race != 'WHITE'],\n",
        "                        privileged_groups=[{sensitive_attribute: 'WHITE'}])\n",
        "reweighed_dataset = reweighing.fit_transform(dataset)"
      ],
      "metadata": {
        "id": "cw6YKRQ7B4cb"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign new weights to the dataset\n",
        "df_filter['sample_weight'] = reweighed_dataset.instance_weights\n",
        "\n",
        "print(\"Bias mitigation applied using Reweighing method. The dataset now includes reweighted sample weights.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsjd63NcAH9E",
        "outputId": "81f05a92-7a52-4b43-852a-4c8de4183979"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bias mitigation applied using Reweighing method. The dataset now includes reweighted sample weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In-Processing Bias Mitigation using Adversarial Debiasing\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "unprivileged_race = 'BLACK'  # Modify based on analysis\n",
        "adversarial_debiasing = AdversarialDebiasing(\n",
        "            privileged_groups=[{sensitive_attribute: 'WHITE'}],\n",
        "            unprivileged_groups=[{sensitive_attribute: unprivileged_race}],\n",
        "            scope_name='adv_debiasing',\n",
        "            sess=tf.compat.v1.Session(),\n",
        "            debias=True\n",
        "        )\n",
        "adversarial_debiasing.fit(dataset)\n",
        "mitigated_predictions = adversarial_debiasing.predict(dataset)\n",
        "\n",
        "print(\"Bias mitigation applied using Adversarial Debiasing (In-Processing). The model is trained to reduce bias.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GWr6JU8AaNw",
        "outputId": "394c3fe0-d701-4a2e-ec78-83abc65582d1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 3.311165; batch adversarial loss: 1.030446\n",
            "epoch 0; iter: 200; batch classifier loss: 0.683279; batch adversarial loss: 0.766853\n",
            "epoch 0; iter: 400; batch classifier loss: 0.521977; batch adversarial loss: 0.538314\n",
            "epoch 0; iter: 600; batch classifier loss: 0.507458; batch adversarial loss: 0.476089\n",
            "epoch 0; iter: 800; batch classifier loss: 0.636375; batch adversarial loss: 0.433462\n",
            "epoch 1; iter: 0; batch classifier loss: 0.600192; batch adversarial loss: 0.364091\n",
            "epoch 1; iter: 200; batch classifier loss: 0.802412; batch adversarial loss: 0.408633\n",
            "epoch 1; iter: 400; batch classifier loss: 0.724761; batch adversarial loss: 0.349326\n",
            "epoch 1; iter: 600; batch classifier loss: 0.601935; batch adversarial loss: 0.326077\n",
            "epoch 1; iter: 800; batch classifier loss: 0.508436; batch adversarial loss: 0.259955\n",
            "epoch 2; iter: 0; batch classifier loss: 0.394206; batch adversarial loss: 0.225049\n",
            "epoch 2; iter: 200; batch classifier loss: 0.464776; batch adversarial loss: 0.203708\n",
            "epoch 2; iter: 400; batch classifier loss: 0.364607; batch adversarial loss: 0.256252\n",
            "epoch 2; iter: 600; batch classifier loss: 0.359013; batch adversarial loss: 0.320255\n",
            "epoch 2; iter: 800; batch classifier loss: 0.396820; batch adversarial loss: 0.238327\n",
            "epoch 3; iter: 0; batch classifier loss: 0.358545; batch adversarial loss: 0.201059\n",
            "epoch 3; iter: 200; batch classifier loss: 0.278313; batch adversarial loss: 0.296194\n",
            "epoch 3; iter: 400; batch classifier loss: 0.405799; batch adversarial loss: 0.310213\n",
            "epoch 3; iter: 600; batch classifier loss: 0.434878; batch adversarial loss: 0.243313\n",
            "epoch 3; iter: 800; batch classifier loss: 0.289488; batch adversarial loss: 0.289062\n",
            "epoch 4; iter: 0; batch classifier loss: 0.407382; batch adversarial loss: 0.269782\n",
            "epoch 4; iter: 200; batch classifier loss: 0.353176; batch adversarial loss: 0.235312\n",
            "epoch 4; iter: 400; batch classifier loss: 0.342961; batch adversarial loss: 0.365848\n",
            "epoch 4; iter: 600; batch classifier loss: 0.412116; batch adversarial loss: 0.194404\n",
            "epoch 4; iter: 800; batch classifier loss: 0.365904; batch adversarial loss: 0.223853\n",
            "epoch 5; iter: 0; batch classifier loss: 0.336098; batch adversarial loss: 0.363234\n",
            "epoch 5; iter: 200; batch classifier loss: 0.332215; batch adversarial loss: 0.191530\n",
            "epoch 5; iter: 400; batch classifier loss: 0.403692; batch adversarial loss: 0.196137\n",
            "epoch 5; iter: 600; batch classifier loss: 0.319977; batch adversarial loss: 0.262165\n",
            "epoch 5; iter: 800; batch classifier loss: 0.374849; batch adversarial loss: 0.280747\n",
            "epoch 6; iter: 0; batch classifier loss: 0.381790; batch adversarial loss: 0.298038\n",
            "epoch 6; iter: 200; batch classifier loss: 0.438889; batch adversarial loss: 0.225509\n",
            "epoch 6; iter: 400; batch classifier loss: 0.417752; batch adversarial loss: 0.278612\n",
            "epoch 6; iter: 600; batch classifier loss: 0.300505; batch adversarial loss: 0.283122\n",
            "epoch 6; iter: 800; batch classifier loss: 0.371211; batch adversarial loss: 0.289532\n",
            "epoch 7; iter: 0; batch classifier loss: 0.300060; batch adversarial loss: 0.294591\n",
            "epoch 7; iter: 200; batch classifier loss: 0.229063; batch adversarial loss: 0.216714\n",
            "epoch 7; iter: 400; batch classifier loss: 0.315437; batch adversarial loss: 0.253568\n",
            "epoch 7; iter: 600; batch classifier loss: 0.402314; batch adversarial loss: 0.193506\n",
            "epoch 7; iter: 800; batch classifier loss: 0.394139; batch adversarial loss: 0.280939\n",
            "epoch 8; iter: 0; batch classifier loss: 0.371963; batch adversarial loss: 0.316075\n",
            "epoch 8; iter: 200; batch classifier loss: 0.311347; batch adversarial loss: 0.273677\n",
            "epoch 8; iter: 400; batch classifier loss: 0.352183; batch adversarial loss: 0.149312\n",
            "epoch 8; iter: 600; batch classifier loss: 0.421161; batch adversarial loss: 0.205177\n",
            "epoch 8; iter: 800; batch classifier loss: 0.299782; batch adversarial loss: 0.255908\n",
            "epoch 9; iter: 0; batch classifier loss: 0.331571; batch adversarial loss: 0.208747\n",
            "epoch 9; iter: 200; batch classifier loss: 0.309757; batch adversarial loss: 0.337347\n",
            "epoch 9; iter: 400; batch classifier loss: 0.441753; batch adversarial loss: 0.222997\n",
            "epoch 9; iter: 600; batch classifier loss: 0.332666; batch adversarial loss: 0.256497\n",
            "epoch 9; iter: 800; batch classifier loss: 0.300162; batch adversarial loss: 0.214598\n",
            "epoch 10; iter: 0; batch classifier loss: 0.359796; batch adversarial loss: 0.386429\n",
            "epoch 10; iter: 200; batch classifier loss: 0.413432; batch adversarial loss: 0.342287\n",
            "epoch 10; iter: 400; batch classifier loss: 0.309849; batch adversarial loss: 0.338779\n",
            "epoch 10; iter: 600; batch classifier loss: 0.280601; batch adversarial loss: 0.241345\n",
            "epoch 10; iter: 800; batch classifier loss: 0.310006; batch adversarial loss: 0.181916\n",
            "epoch 11; iter: 0; batch classifier loss: 0.463254; batch adversarial loss: 0.234047\n",
            "epoch 11; iter: 200; batch classifier loss: 0.293983; batch adversarial loss: 0.301788\n",
            "epoch 11; iter: 400; batch classifier loss: 0.291411; batch adversarial loss: 0.229826\n",
            "epoch 11; iter: 600; batch classifier loss: 0.285536; batch adversarial loss: 0.364217\n",
            "epoch 11; iter: 800; batch classifier loss: 0.303398; batch adversarial loss: 0.295782\n",
            "epoch 12; iter: 0; batch classifier loss: 0.401025; batch adversarial loss: 0.271891\n",
            "epoch 12; iter: 200; batch classifier loss: 0.362821; batch adversarial loss: 0.202794\n",
            "epoch 12; iter: 400; batch classifier loss: 0.269612; batch adversarial loss: 0.245129\n",
            "epoch 12; iter: 600; batch classifier loss: 0.413581; batch adversarial loss: 0.158872\n",
            "epoch 12; iter: 800; batch classifier loss: 0.349008; batch adversarial loss: 0.215719\n",
            "epoch 13; iter: 0; batch classifier loss: 0.321916; batch adversarial loss: 0.389129\n",
            "epoch 13; iter: 200; batch classifier loss: 0.354241; batch adversarial loss: 0.268652\n",
            "epoch 13; iter: 400; batch classifier loss: 0.427146; batch adversarial loss: 0.282852\n",
            "epoch 13; iter: 600; batch classifier loss: 0.282474; batch adversarial loss: 0.229484\n",
            "epoch 13; iter: 800; batch classifier loss: 0.361014; batch adversarial loss: 0.264542\n",
            "epoch 14; iter: 0; batch classifier loss: 0.337602; batch adversarial loss: 0.259190\n",
            "epoch 14; iter: 200; batch classifier loss: 0.360260; batch adversarial loss: 0.252869\n",
            "epoch 14; iter: 400; batch classifier loss: 0.283913; batch adversarial loss: 0.228686\n",
            "epoch 14; iter: 600; batch classifier loss: 0.369233; batch adversarial loss: 0.310692\n",
            "epoch 14; iter: 800; batch classifier loss: 0.355957; batch adversarial loss: 0.330598\n",
            "epoch 15; iter: 0; batch classifier loss: 0.324927; batch adversarial loss: 0.310057\n",
            "epoch 15; iter: 200; batch classifier loss: 0.364438; batch adversarial loss: 0.223563\n",
            "epoch 15; iter: 400; batch classifier loss: 0.399057; batch adversarial loss: 0.391721\n",
            "epoch 15; iter: 600; batch classifier loss: 0.309929; batch adversarial loss: 0.215254\n",
            "epoch 15; iter: 800; batch classifier loss: 0.268007; batch adversarial loss: 0.233252\n",
            "epoch 16; iter: 0; batch classifier loss: 0.322171; batch adversarial loss: 0.246689\n",
            "epoch 16; iter: 200; batch classifier loss: 0.290930; batch adversarial loss: 0.274579\n",
            "epoch 16; iter: 400; batch classifier loss: 0.318860; batch adversarial loss: 0.215385\n",
            "epoch 16; iter: 600; batch classifier loss: 0.283035; batch adversarial loss: 0.365871\n",
            "epoch 16; iter: 800; batch classifier loss: 0.366440; batch adversarial loss: 0.281344\n",
            "epoch 17; iter: 0; batch classifier loss: 0.334796; batch adversarial loss: 0.201010\n",
            "epoch 17; iter: 200; batch classifier loss: 0.373585; batch adversarial loss: 0.222721\n",
            "epoch 17; iter: 400; batch classifier loss: 0.347624; batch adversarial loss: 0.301638\n",
            "epoch 17; iter: 600; batch classifier loss: 0.291505; batch adversarial loss: 0.267864\n",
            "epoch 17; iter: 800; batch classifier loss: 0.358521; batch adversarial loss: 0.262203\n",
            "epoch 18; iter: 0; batch classifier loss: 0.372767; batch adversarial loss: 0.197464\n",
            "epoch 18; iter: 200; batch classifier loss: 0.347799; batch adversarial loss: 0.246657\n",
            "epoch 18; iter: 400; batch classifier loss: 0.336160; batch adversarial loss: 0.190254\n",
            "epoch 18; iter: 600; batch classifier loss: 0.341961; batch adversarial loss: 0.201357\n",
            "epoch 18; iter: 800; batch classifier loss: 0.343675; batch adversarial loss: 0.168770\n",
            "epoch 19; iter: 0; batch classifier loss: 0.347761; batch adversarial loss: 0.243834\n",
            "epoch 19; iter: 200; batch classifier loss: 0.323872; batch adversarial loss: 0.219545\n",
            "epoch 19; iter: 400; batch classifier loss: 0.370406; batch adversarial loss: 0.203423\n",
            "epoch 19; iter: 600; batch classifier loss: 0.308561; batch adversarial loss: 0.354081\n",
            "epoch 19; iter: 800; batch classifier loss: 0.324968; batch adversarial loss: 0.320922\n",
            "epoch 20; iter: 0; batch classifier loss: 0.227574; batch adversarial loss: 0.258019\n",
            "epoch 20; iter: 200; batch classifier loss: 0.390102; batch adversarial loss: 0.249671\n",
            "epoch 20; iter: 400; batch classifier loss: 0.395111; batch adversarial loss: 0.274201\n",
            "epoch 20; iter: 600; batch classifier loss: 0.387160; batch adversarial loss: 0.233413\n",
            "epoch 20; iter: 800; batch classifier loss: 0.518983; batch adversarial loss: 0.308878\n",
            "epoch 21; iter: 0; batch classifier loss: 0.301194; batch adversarial loss: 0.367576\n",
            "epoch 21; iter: 200; batch classifier loss: 0.306651; batch adversarial loss: 0.256163\n",
            "epoch 21; iter: 400; batch classifier loss: 0.379714; batch adversarial loss: 0.257776\n",
            "epoch 21; iter: 600; batch classifier loss: 0.349596; batch adversarial loss: 0.339381\n",
            "epoch 21; iter: 800; batch classifier loss: 0.458095; batch adversarial loss: 0.215060\n",
            "epoch 22; iter: 0; batch classifier loss: 0.361025; batch adversarial loss: 0.205352\n",
            "epoch 22; iter: 200; batch classifier loss: 0.287075; batch adversarial loss: 0.235570\n",
            "epoch 22; iter: 400; batch classifier loss: 0.267811; batch adversarial loss: 0.214350\n",
            "epoch 22; iter: 600; batch classifier loss: 0.320809; batch adversarial loss: 0.185046\n",
            "epoch 22; iter: 800; batch classifier loss: 0.322587; batch adversarial loss: 0.323458\n",
            "epoch 23; iter: 0; batch classifier loss: 0.318992; batch adversarial loss: 0.214062\n",
            "epoch 23; iter: 200; batch classifier loss: 0.379928; batch adversarial loss: 0.301794\n",
            "epoch 23; iter: 400; batch classifier loss: 0.381251; batch adversarial loss: 0.296029\n",
            "epoch 23; iter: 600; batch classifier loss: 0.319126; batch adversarial loss: 0.164251\n",
            "epoch 23; iter: 800; batch classifier loss: 0.428306; batch adversarial loss: 0.198355\n",
            "epoch 24; iter: 0; batch classifier loss: 0.404872; batch adversarial loss: 0.246001\n",
            "epoch 24; iter: 200; batch classifier loss: 0.307609; batch adversarial loss: 0.338006\n",
            "epoch 24; iter: 400; batch classifier loss: 0.412586; batch adversarial loss: 0.235288\n",
            "epoch 24; iter: 600; batch classifier loss: 0.378471; batch adversarial loss: 0.289629\n",
            "epoch 24; iter: 800; batch classifier loss: 0.282007; batch adversarial loss: 0.188080\n",
            "epoch 25; iter: 0; batch classifier loss: 0.261157; batch adversarial loss: 0.331333\n",
            "epoch 25; iter: 200; batch classifier loss: 0.343505; batch adversarial loss: 0.317671\n",
            "epoch 25; iter: 400; batch classifier loss: 0.329864; batch adversarial loss: 0.241238\n",
            "epoch 25; iter: 600; batch classifier loss: 0.391963; batch adversarial loss: 0.200112\n",
            "epoch 25; iter: 800; batch classifier loss: 0.441407; batch adversarial loss: 0.217075\n",
            "epoch 26; iter: 0; batch classifier loss: 0.282810; batch adversarial loss: 0.219151\n",
            "epoch 26; iter: 200; batch classifier loss: 0.316394; batch adversarial loss: 0.243643\n",
            "epoch 26; iter: 400; batch classifier loss: 0.252057; batch adversarial loss: 0.265832\n",
            "epoch 26; iter: 600; batch classifier loss: 0.305822; batch adversarial loss: 0.253983\n",
            "epoch 26; iter: 800; batch classifier loss: 0.299212; batch adversarial loss: 0.269781\n",
            "epoch 27; iter: 0; batch classifier loss: 0.334356; batch adversarial loss: 0.238752\n",
            "epoch 27; iter: 200; batch classifier loss: 0.392361; batch adversarial loss: 0.244780\n",
            "epoch 27; iter: 400; batch classifier loss: 0.305080; batch adversarial loss: 0.232293\n",
            "epoch 27; iter: 600; batch classifier loss: 0.341544; batch adversarial loss: 0.359002\n",
            "epoch 27; iter: 800; batch classifier loss: 0.359247; batch adversarial loss: 0.288820\n",
            "epoch 28; iter: 0; batch classifier loss: 0.301277; batch adversarial loss: 0.191680\n",
            "epoch 28; iter: 200; batch classifier loss: 0.289788; batch adversarial loss: 0.292813\n",
            "epoch 28; iter: 400; batch classifier loss: 0.324603; batch adversarial loss: 0.251388\n",
            "epoch 28; iter: 600; batch classifier loss: 0.300023; batch adversarial loss: 0.176712\n",
            "epoch 28; iter: 800; batch classifier loss: 0.319796; batch adversarial loss: 0.234060\n",
            "epoch 29; iter: 0; batch classifier loss: 0.363046; batch adversarial loss: 0.198922\n",
            "epoch 29; iter: 200; batch classifier loss: 0.300027; batch adversarial loss: 0.362706\n",
            "epoch 29; iter: 400; batch classifier loss: 0.281091; batch adversarial loss: 0.350791\n",
            "epoch 29; iter: 600; batch classifier loss: 0.379374; batch adversarial loss: 0.269476\n",
            "epoch 29; iter: 800; batch classifier loss: 0.282283; batch adversarial loss: 0.348119\n",
            "epoch 30; iter: 0; batch classifier loss: 0.470992; batch adversarial loss: 0.315807\n",
            "epoch 30; iter: 200; batch classifier loss: 0.326324; batch adversarial loss: 0.274794\n",
            "epoch 30; iter: 400; batch classifier loss: 0.327119; batch adversarial loss: 0.291751\n",
            "epoch 30; iter: 600; batch classifier loss: 0.320627; batch adversarial loss: 0.305420\n",
            "epoch 30; iter: 800; batch classifier loss: 0.261030; batch adversarial loss: 0.246518\n",
            "epoch 31; iter: 0; batch classifier loss: 0.462837; batch adversarial loss: 0.235708\n",
            "epoch 31; iter: 200; batch classifier loss: 0.354415; batch adversarial loss: 0.275938\n",
            "epoch 31; iter: 400; batch classifier loss: 0.364689; batch adversarial loss: 0.236936\n",
            "epoch 31; iter: 600; batch classifier loss: 0.387313; batch adversarial loss: 0.209690\n",
            "epoch 31; iter: 800; batch classifier loss: 0.307856; batch adversarial loss: 0.324816\n",
            "epoch 32; iter: 0; batch classifier loss: 0.321493; batch adversarial loss: 0.270090\n",
            "epoch 32; iter: 200; batch classifier loss: 0.302893; batch adversarial loss: 0.148118\n",
            "epoch 32; iter: 400; batch classifier loss: 0.355612; batch adversarial loss: 0.265629\n",
            "epoch 32; iter: 600; batch classifier loss: 0.403912; batch adversarial loss: 0.363327\n",
            "epoch 32; iter: 800; batch classifier loss: 0.373726; batch adversarial loss: 0.268397\n",
            "epoch 33; iter: 0; batch classifier loss: 0.389510; batch adversarial loss: 0.211777\n",
            "epoch 33; iter: 200; batch classifier loss: 0.326990; batch adversarial loss: 0.209330\n",
            "epoch 33; iter: 400; batch classifier loss: 0.309908; batch adversarial loss: 0.310282\n",
            "epoch 33; iter: 600; batch classifier loss: 0.324259; batch adversarial loss: 0.359666\n",
            "epoch 33; iter: 800; batch classifier loss: 0.335104; batch adversarial loss: 0.215049\n",
            "epoch 34; iter: 0; batch classifier loss: 0.301611; batch adversarial loss: 0.330594\n",
            "epoch 34; iter: 200; batch classifier loss: 0.417301; batch adversarial loss: 0.274721\n",
            "epoch 34; iter: 400; batch classifier loss: 0.330025; batch adversarial loss: 0.245055\n",
            "epoch 34; iter: 600; batch classifier loss: 0.345100; batch adversarial loss: 0.319388\n",
            "epoch 34; iter: 800; batch classifier loss: 0.277304; batch adversarial loss: 0.209295\n",
            "epoch 35; iter: 0; batch classifier loss: 0.364771; batch adversarial loss: 0.186393\n",
            "epoch 35; iter: 200; batch classifier loss: 0.339188; batch adversarial loss: 0.319474\n",
            "epoch 35; iter: 400; batch classifier loss: 0.198610; batch adversarial loss: 0.251480\n",
            "epoch 35; iter: 600; batch classifier loss: 0.313389; batch adversarial loss: 0.187929\n",
            "epoch 35; iter: 800; batch classifier loss: 0.402687; batch adversarial loss: 0.195779\n",
            "epoch 36; iter: 0; batch classifier loss: 0.285987; batch adversarial loss: 0.217456\n",
            "epoch 36; iter: 200; batch classifier loss: 0.288767; batch adversarial loss: 0.389723\n",
            "epoch 36; iter: 400; batch classifier loss: 0.308393; batch adversarial loss: 0.270411\n",
            "epoch 36; iter: 600; batch classifier loss: 0.389708; batch adversarial loss: 0.305574\n",
            "epoch 36; iter: 800; batch classifier loss: 0.331079; batch adversarial loss: 0.200164\n",
            "epoch 37; iter: 0; batch classifier loss: 0.334853; batch adversarial loss: 0.217792\n",
            "epoch 37; iter: 200; batch classifier loss: 0.386094; batch adversarial loss: 0.202118\n",
            "epoch 37; iter: 400; batch classifier loss: 0.263185; batch adversarial loss: 0.215015\n",
            "epoch 37; iter: 600; batch classifier loss: 0.431267; batch adversarial loss: 0.193576\n",
            "epoch 37; iter: 800; batch classifier loss: 0.347053; batch adversarial loss: 0.163865\n",
            "epoch 38; iter: 0; batch classifier loss: 0.385104; batch adversarial loss: 0.227400\n",
            "epoch 38; iter: 200; batch classifier loss: 0.305689; batch adversarial loss: 0.264345\n",
            "epoch 38; iter: 400; batch classifier loss: 0.372822; batch adversarial loss: 0.265456\n",
            "epoch 38; iter: 600; batch classifier loss: 0.292815; batch adversarial loss: 0.226985\n",
            "epoch 38; iter: 800; batch classifier loss: 0.376252; batch adversarial loss: 0.303583\n",
            "epoch 39; iter: 0; batch classifier loss: 0.298598; batch adversarial loss: 0.271900\n",
            "epoch 39; iter: 200; batch classifier loss: 0.274740; batch adversarial loss: 0.345637\n",
            "epoch 39; iter: 400; batch classifier loss: 0.360861; batch adversarial loss: 0.335022\n",
            "epoch 39; iter: 600; batch classifier loss: 0.294654; batch adversarial loss: 0.383206\n",
            "epoch 39; iter: 800; batch classifier loss: 0.295321; batch adversarial loss: 0.262841\n",
            "epoch 40; iter: 0; batch classifier loss: 0.293179; batch adversarial loss: 0.394754\n",
            "epoch 40; iter: 200; batch classifier loss: 0.290885; batch adversarial loss: 0.382237\n",
            "epoch 40; iter: 400; batch classifier loss: 0.283832; batch adversarial loss: 0.186463\n",
            "epoch 40; iter: 600; batch classifier loss: 0.377858; batch adversarial loss: 0.286639\n",
            "epoch 40; iter: 800; batch classifier loss: 0.334630; batch adversarial loss: 0.239353\n",
            "epoch 41; iter: 0; batch classifier loss: 0.366838; batch adversarial loss: 0.231142\n",
            "epoch 41; iter: 200; batch classifier loss: 0.377448; batch adversarial loss: 0.213488\n",
            "epoch 41; iter: 400; batch classifier loss: 0.270559; batch adversarial loss: 0.184116\n",
            "epoch 41; iter: 600; batch classifier loss: 0.359830; batch adversarial loss: 0.342856\n",
            "epoch 41; iter: 800; batch classifier loss: 0.429978; batch adversarial loss: 0.326390\n",
            "epoch 42; iter: 0; batch classifier loss: 0.265582; batch adversarial loss: 0.171745\n",
            "epoch 42; iter: 200; batch classifier loss: 0.448993; batch adversarial loss: 0.215761\n",
            "epoch 42; iter: 400; batch classifier loss: 0.375750; batch adversarial loss: 0.249765\n",
            "epoch 42; iter: 600; batch classifier loss: 0.407004; batch adversarial loss: 0.286703\n",
            "epoch 42; iter: 800; batch classifier loss: 0.287248; batch adversarial loss: 0.268789\n",
            "epoch 43; iter: 0; batch classifier loss: 0.408497; batch adversarial loss: 0.287715\n",
            "epoch 43; iter: 200; batch classifier loss: 0.261276; batch adversarial loss: 0.272501\n",
            "epoch 43; iter: 400; batch classifier loss: 0.297328; batch adversarial loss: 0.235287\n",
            "epoch 43; iter: 600; batch classifier loss: 0.417539; batch adversarial loss: 0.245418\n",
            "epoch 43; iter: 800; batch classifier loss: 0.356407; batch adversarial loss: 0.287651\n",
            "epoch 44; iter: 0; batch classifier loss: 0.285469; batch adversarial loss: 0.279230\n",
            "epoch 44; iter: 200; batch classifier loss: 0.286515; batch adversarial loss: 0.248581\n",
            "epoch 44; iter: 400; batch classifier loss: 0.402016; batch adversarial loss: 0.302316\n",
            "epoch 44; iter: 600; batch classifier loss: 0.347631; batch adversarial loss: 0.257068\n",
            "epoch 44; iter: 800; batch classifier loss: 0.394950; batch adversarial loss: 0.337196\n",
            "epoch 45; iter: 0; batch classifier loss: 0.362410; batch adversarial loss: 0.274049\n",
            "epoch 45; iter: 200; batch classifier loss: 0.320872; batch adversarial loss: 0.250685\n",
            "epoch 45; iter: 400; batch classifier loss: 0.352982; batch adversarial loss: 0.181473\n",
            "epoch 45; iter: 600; batch classifier loss: 0.409955; batch adversarial loss: 0.282999\n",
            "epoch 45; iter: 800; batch classifier loss: 0.296640; batch adversarial loss: 0.242305\n",
            "epoch 46; iter: 0; batch classifier loss: 0.316543; batch adversarial loss: 0.222443\n",
            "epoch 46; iter: 200; batch classifier loss: 0.332908; batch adversarial loss: 0.286782\n",
            "epoch 46; iter: 400; batch classifier loss: 0.327882; batch adversarial loss: 0.339569\n",
            "epoch 46; iter: 600; batch classifier loss: 0.402590; batch adversarial loss: 0.311279\n",
            "epoch 46; iter: 800; batch classifier loss: 0.323619; batch adversarial loss: 0.169006\n",
            "epoch 47; iter: 0; batch classifier loss: 0.327390; batch adversarial loss: 0.247326\n",
            "epoch 47; iter: 200; batch classifier loss: 0.357236; batch adversarial loss: 0.261420\n",
            "epoch 47; iter: 400; batch classifier loss: 0.380768; batch adversarial loss: 0.365792\n",
            "epoch 47; iter: 600; batch classifier loss: 0.347709; batch adversarial loss: 0.247586\n",
            "epoch 47; iter: 800; batch classifier loss: 0.359575; batch adversarial loss: 0.311786\n",
            "epoch 48; iter: 0; batch classifier loss: 0.319944; batch adversarial loss: 0.298294\n",
            "epoch 48; iter: 200; batch classifier loss: 0.349861; batch adversarial loss: 0.332317\n",
            "epoch 48; iter: 400; batch classifier loss: 0.398998; batch adversarial loss: 0.270323\n",
            "epoch 48; iter: 600; batch classifier loss: 0.377827; batch adversarial loss: 0.218339\n",
            "epoch 48; iter: 800; batch classifier loss: 0.298046; batch adversarial loss: 0.237268\n",
            "epoch 49; iter: 0; batch classifier loss: 0.239516; batch adversarial loss: 0.255118\n",
            "epoch 49; iter: 200; batch classifier loss: 0.216419; batch adversarial loss: 0.264912\n",
            "epoch 49; iter: 400; batch classifier loss: 0.324389; batch adversarial loss: 0.185538\n",
            "epoch 49; iter: 600; batch classifier loss: 0.243752; batch adversarial loss: 0.297686\n",
            "epoch 49; iter: 800; batch classifier loss: 0.335769; batch adversarial loss: 0.305350\n",
            "Bias mitigation applied using Adversarial Debiasing (In-Processing). The model is trained to reduce bias.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare Models Before and After Debiasing\n",
        "original_predictions = dataset.labels\n",
        "#mitigated_predictions = mitigated_predictions.labels\n",
        "\n",
        "# Performance Metrics\n",
        "accuracy_before = accuracy_score(original_predictions, df_filter['FRISKED_FLAG'])\n",
        "accuracy_after = accuracy_score(mitigated_predictions, df_filter['FRISKED_FLAG'])\n",
        "f1_before = f1_score(original_predictions, df_filter['FRISKED_FLAG'])\n",
        "f1_after = f1_score(mitigated_predictions, df_filter['FRISKED_FLAG'])\n",
        "\n",
        "print(\"\\nModel Performance Comparison:\")\n",
        "print(f\"Accuracy Before Debiasing: {accuracy_before:.4f}\")\n",
        "print(f\"Accuracy After Debiasing: {accuracy_after:.4f}\")\n",
        "print(f\"F1 Score Before Debiasing: {f1_before:.4f}\")\n",
        "print(f\"F1 Score After Debiasing: {f1_after:.4f}\")\n",
        "\n",
        "# Fairness Metrics Comparison\n",
        "eod_after, di_after, spd_after = calculate_bias_metrics(df_filter, privileged_race)\n",
        "\n",
        "print(\"\\nFairness Metrics Comparison:\")\n",
        "print(\"Equal Opportunity Difference Before:\", eod)\n",
        "print(\"Equal Opportunity Difference After:\", eod_after)\n",
        "print(\"Disparate Impact Before:\", di)\n",
        "print(\"Disparate Impact After:\", di_after)\n",
        "print(\"Statistical Parity Difference Before:\", spd)\n",
        "print(\"Statistical Parity Difference After:\", spd_after)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjXlmd38Bfrv",
        "outputId": "8f5b84ca-ded7-4ff2-ba99-ff2b348d30ca"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance Comparison:\n",
            "Accuracy Before Debiasing: 1.0000\n",
            "Accuracy After Debiasing: 0.8607\n",
            "F1 Score Before Debiasing: 1.0000\n",
            "F1 Score After Debiasing: 0.8825\n",
            "privileged_rate : 0.5790337913749892\n",
            "rates : {'WHITE HISPANIC': np.float64(0.5790337913749892), 'BLACK': np.float64(0.6296427253720329), 'BLACK HISPANIC': np.float64(0.6308646762310973), 'WHITE': np.float64(0.3846340575312538), 'MIDDLE EASTERN/SOUTHWEST ASIAN': np.float64(0.47295423023578365), 'ASIAN / PACIFIC ISLANDER': np.float64(0.4738771769019248), 'AMERICAN INDIAN/ALASKAN NATIVE': np.float64(0.410958904109589)}\n",
            "\n",
            "Fairness Metrics Comparison:\n",
            "Equal Opportunity Difference Before: {'WHITE HISPANIC': np.float64(0.0), 'BLACK': np.float64(0.05060893399704369), 'BLACK HISPANIC': np.float64(0.051830884856108095), 'WHITE': np.float64(-0.19439973384373543), 'MIDDLE EASTERN/SOUTHWEST ASIAN': np.float64(-0.10607956113920558), 'ASIAN / PACIFIC ISLANDER': np.float64(-0.1051566144730644), 'AMERICAN INDIAN/ALASKAN NATIVE': np.float64(-0.1680748872654002)}\n",
            "Equal Opportunity Difference After: {'WHITE HISPANIC': np.float64(0.0), 'BLACK': np.float64(0.05060893399704369), 'BLACK HISPANIC': np.float64(0.051830884856108095), 'WHITE': np.float64(-0.19439973384373543), 'MIDDLE EASTERN/SOUTHWEST ASIAN': np.float64(-0.10607956113920558), 'ASIAN / PACIFIC ISLANDER': np.float64(-0.1051566144730644), 'AMERICAN INDIAN/ALASKAN NATIVE': np.float64(-0.1680748872654002)}\n",
            "Disparate Impact Before: {'WHITE HISPANIC': np.float64(1.0), 'BLACK': np.float64(1.0874023843701184), 'BLACK HISPANIC': np.float64(1.089512711741795), 'WHITE': np.float64(0.6642687581633041), 'MIDDLE EASTERN/SOUTHWEST ASIAN': np.float64(0.81679901463556), 'ASIAN / PACIFIC ISLANDER': np.float64(0.8183929573033092), 'AMERICAN INDIAN/ALASKAN NATIVE': np.float64(0.7097321611122469)}\n",
            "Disparate Impact After: {'WHITE HISPANIC': np.float64(1.0), 'BLACK': np.float64(1.0874023843701184), 'BLACK HISPANIC': np.float64(1.089512711741795), 'WHITE': np.float64(0.6642687581633041), 'MIDDLE EASTERN/SOUTHWEST ASIAN': np.float64(0.81679901463556), 'ASIAN / PACIFIC ISLANDER': np.float64(0.8183929573033092), 'AMERICAN INDIAN/ALASKAN NATIVE': np.float64(0.7097321611122469)}\n",
            "Statistical Parity Difference Before: {'WHITE HISPANIC': np.float64(0.0), 'BLACK': np.float64(0.05060893399704369), 'BLACK HISPANIC': np.float64(0.051830884856108095), 'WHITE': np.float64(-0.19439973384373543), 'MIDDLE EASTERN/SOUTHWEST ASIAN': np.float64(-0.10607956113920558), 'ASIAN / PACIFIC ISLANDER': np.float64(-0.1051566144730644), 'AMERICAN INDIAN/ALASKAN NATIVE': np.float64(-0.1680748872654002)}\n",
            "Statistical Parity Difference After: {'WHITE HISPANIC': np.float64(0.0), 'BLACK': np.float64(0.05060893399704369), 'BLACK HISPANIC': np.float64(0.051830884856108095), 'WHITE': np.float64(-0.19439973384373543), 'MIDDLE EASTERN/SOUTHWEST ASIAN': np.float64(-0.10607956113920558), 'ASIAN / PACIFIC ISLANDER': np.float64(-0.1051566144730644), 'AMERICAN INDIAN/ALASKAN NATIVE': np.float64(-0.1680748872654002)}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}